{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOtd5zddUaL0CkSGWa9299a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HaeChan0305/Sentence-Type-Classifier/blob/main/Sentence_Type_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CVS_fdJAjDE"
      },
      "source": [
        "# cal spc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oiq9pa49B4lp"
      },
      "outputs": [],
      "source": [
        "def find_root(doc):\n",
        "    for token in doc:\n",
        "        if token.dep_ == 'ROOT':\n",
        "            return token\n",
        "\n",
        "def find_all_root(doc):\n",
        "    roots = []\n",
        "    for token in doc:\n",
        "        if token.dep_ == 'ROOT':\n",
        "            roots.append(token)\n",
        "\n",
        "    return roots\n",
        "          \n",
        "def walk_tree(doc, token, depths, depth):\n",
        "    children = list(token.children)\n",
        "    if len(children) > 0:\n",
        "        for child in children:\n",
        "            depths[child.i] = depth\n",
        "            depths = walk_tree(doc, child, depths, depth + 1)\n",
        "\n",
        "    return depths\n",
        "\n",
        "def children_of_children(token):\n",
        "    children = list(token.children)\n",
        "    \n",
        "    if len(children) == 0:\n",
        "        return []\n",
        "    \n",
        "    result = []\n",
        "    for child in list(token.children):\n",
        "        result += children_of_children(child)\n",
        "\n",
        "    return result + children\n",
        "\n",
        "def right_upper_ancestor(token):\n",
        "    for ancestor in list(token.ancestors):\n",
        "          if token in list(ancestor.children):\n",
        "                return ancestor\n",
        "\n",
        "def is_verb(token):\n",
        "    return token.pos_ == \"VERB\" or (token.pos_ == \"AUX\" and len(list(token.children)) > 0)\n",
        "\n",
        "def have_subj_child(token):\n",
        "    for child in children_of_children(token):\n",
        "        if child.dep_ == 'nsubj' or child.dep_ == 'csubj' or child.dep_ == 'nsubjpass':\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "def is_to_V(token):\n",
        "    for child in list(token.children):\n",
        "        if child.text == 'to' and child.dep_ == 'aux':\n",
        "            return True\n",
        "    return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QbFckjgrB4rz"
      },
      "outputs": [],
      "source": [
        "def is_main_verb(token):\n",
        "    if not is_verb(token):\n",
        "        return False\n",
        "\n",
        "    prep = ['after', 'as', 'before', 'despite', 'lest', 'since', 'supposing', 'than', 'till', 'until']\n",
        "    ignore_dep = ['xcomp', 'acl', 'acomp', 'amod', 'prep', 'auxpass', 'dep']\n",
        "    need_subj_dep = ['csubj', 'advcl', 'relcl']\n",
        "    causative_verb = ['make', 'have', 'let', 'help', 'get']\n",
        "\n",
        "    if token.dep_ == 'ROOT':\n",
        "        return True\n",
        "\n",
        "    elif token.dep_ in ignore_dep:\n",
        "        return False\n",
        "\n",
        "    elif token.dep_ in need_subj_dep:\n",
        "        return have_subj_child(token) and not is_to_V(token)\n",
        "\n",
        "    elif token.dep_ == 'conj':\n",
        "        ancestor = right_upper_ancestor(token)\n",
        "        return is_main_verb(ancestor)\n",
        "          \n",
        "    elif token.dep_ == 'pcomp':\n",
        "        ancestor = right_upper_ancestor(token)\n",
        "        return ((ancestor.dep_ == 'prep') and (ancestor.text.lower() in prep)) or have_subj_child(token)\n",
        "            \n",
        "    elif token.dep_ == 'ccomp':\n",
        "        if is_to_V(token):\n",
        "            return False\n",
        "        # causative_verb detect\n",
        "        ancestor = right_upper_ancestor(token)\n",
        "        if (ancestor.lemma_ in causative_verb) and (ancestor.i < token.i):\n",
        "            if 'nsubj' in [child.dep_ for child in list(token.children)]:\n",
        "                index_list = list(range(ancestor.i+1,token.i))\n",
        "                for child in children_of_children(token):\n",
        "                    if child.i in index_list:\n",
        "                        index_list.remove(child.i)\n",
        "                if not len(index_list):\n",
        "                    return False\n",
        "        else:\n",
        "          return True\n",
        "\n",
        "    else:\n",
        "      return False\n",
        "\n",
        "def find_main_verbs(doc):\n",
        "    main_verbs = []\n",
        "    for token in doc:\n",
        "        if is_main_verb(token):\n",
        "            main_verbs.append(token)\n",
        "    \n",
        "    return main_verbs\n",
        "\n",
        "\n",
        "def is_indep_verb(verb, main_verbs, doc):\n",
        "    if verb.dep_ == 'ROOT' or verb.dep_ == 'conj':\n",
        "        return True\n",
        "      \n",
        "    elif verb.dep_ == 'ccomp':\n",
        "        for token in doc:\n",
        "            if token.text.lower() == 'so':\n",
        "                anc = right_upper_ancestor(token)\n",
        "                #print(anc)\n",
        "                if anc == None:\n",
        "                    continue\n",
        "                if anc.i == verb.i:\n",
        "                    return True\n",
        "                elif anc.dep_ == 'ROOT' and verb.i < anc.i:\n",
        "                    return True\n",
        "\n",
        "\n",
        "            elif token.tag_ == ':':\n",
        "                anc = right_upper_ancestor(verb)\n",
        "                if anc == None:\n",
        "                    continue\n",
        "                if anc.dep_ == 'ROOT' and (anc.i - token.i) * (token.i - verb.i) > 0:\n",
        "                    return True\n",
        "            \n",
        "        return False\n",
        "\n",
        "    elif verb.dep_ == 'advcl':\n",
        "        for token in doc:\n",
        "            if token.text.lower() == 'for' and token.dep_ == 'mark':\n",
        "                #print(right_upper_ancestor(token))\n",
        "                if right_upper_ancestor(token) == None:\n",
        "                    continue\n",
        "                if right_upper_ancestor(token).i == verb.i:\n",
        "                    return True \n",
        "\n",
        "            elif token.text.lower() == 'so':\n",
        "                #print(right_upper_ancestor(token))\n",
        "                if right_upper_ancestor(token) == None:\n",
        "                    continue\n",
        "                if right_upper_ancestor(token).i == verb.i:\n",
        "                    return True     \n",
        "\n",
        "        return False\n",
        "\n",
        "    else:\n",
        "      return False     \n",
        "                \n",
        "\n",
        "def find_indep_verbs(doc):\n",
        "    main_verbs = find_main_verbs(doc)\n",
        "\n",
        "    result = []\n",
        "    for verb in main_verbs:\n",
        "        if is_indep_verb(verb, main_verbs, doc):\n",
        "            result.append(verb)\n",
        "        else:\n",
        "            pass\n",
        "            \n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sentence_type_ratio(docs):\n",
        "  result = {\n",
        "      \"simple\" : 0,\n",
        "      \"complex\" : 0,\n",
        "      \"compound\" : 0,\n",
        "      \"cc\" : 0,\n",
        "      \"except\" : 0\n",
        "  }\n",
        "\n",
        "  for doc in docs:\n",
        "    num_indep_verbs = len(find_indep_verbs(doc))\n",
        "    num_dep_verbs = len(find_main_verbs(doc)) - num_indep_verbs\n",
        "\n",
        "    if num_indep_verbs == 0:\n",
        "      result[\"except\"] += 1\n",
        "      # print(f\"except : {doc}\")\n",
        "\n",
        "    elif num_indep_verbs == 1:\n",
        "      if num_dep_verbs == 0:\n",
        "        result[\"simple\"] += 1\n",
        "        # print(f\"simple : {doc}\")\n",
        "      else:\n",
        "        result[\"complex\"] += 1\n",
        "        # print(f\"complex : {doc}\")\n",
        "    \n",
        "    else:\n",
        "      if num_dep_verbs == 0:\n",
        "        result[\"compound\"] += 1\n",
        "        # print(f\"compound : {doc}\")\n",
        "      else:\n",
        "        result[\"cc\"] += 1\n",
        "        # print(f\"cc : {doc}\")\n",
        "\n",
        "  return result"
      ],
      "metadata": {
        "id": "XrOeAVn-N-4X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2eN4qxztCWGq"
      },
      "outputs": [],
      "source": [
        "def sub_clause_per_cunit_all_turns(docs):\n",
        "  num_cunit = 0\n",
        "  num_clause = 0\n",
        "  num_sub_clause = 0\n",
        "\n",
        "  for doc in docs:\n",
        "    num_cunit_turn = len(find_indep_verbs(doc))\n",
        "    num_clause_turn = len(find_main_verbs(doc))\n",
        "    num_sub_clause_turn = num_clause_turn - num_cunit_turn\n",
        "\n",
        "    num_cunit += num_cunit_turn\n",
        "    num_clause += num_clause_turn\n",
        "    num_sub_clause += num_sub_clause_turn\n",
        "\n",
        "  try:\n",
        "    spc = num_sub_clause/num_cunit\n",
        "  except:\n",
        "    spc = None\n",
        "  \n",
        "  return spc"
      ]
    }
  ]
}